# WhisperSwiftKey

Native macOS speech-to-text keyboard input using [WhisperKit](https://github.com/argmaxinc/WhisperKit) â€” 100% on-device, zero cloud dependency.

## Features (Planned)
- ğŸ¤ Double-tap Fn to dictate, text appears at cursor
- ğŸ”’ Completely on-device â€” no audio ever leaves your Mac
- âš¡ Optimized for Apple Silicon (M1/M2/M3/M4)
- ğŸ“– Custom dictionary for names, jargon, technical terms
- ğŸ¯ Push-to-talk and tap-to-toggle modes
- ğŸŒ 58 language support with auto-detection
- ğŸ“Š Transcription history with search
- ğŸ¤– Optional AI agent mode (local LLM post-processing)

## Requirements
- macOS 14.0+ (Sonoma)
- Apple Silicon (M1 or later)
- Xcode 15.0+
- Microphone permission
- Accessibility permission (for text insertion)

## Building
1. Open `WhisperSwiftKey.xcodeproj` in Xcode
2. Select your signing team
3. Build & Run (âŒ˜R)

## Architecture
- **SwiftUI** menu bar app (no dock icon)
- **WhisperKit** for on-device speech recognition
- **SwiftData** for transcription history
- **CGEvent** tap for global hotkey detection
- **Accessibility API** for text insertion at cursor

## License
MIT
